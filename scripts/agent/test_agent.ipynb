{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falcon-Eye Agent Test Notebook\n",
    "\n",
    "Test agents locally by connecting to a running Falcon-Eye API backend.\n",
    "\n",
    "**What this does:**\n",
    "- Connects to your backend API to fetch agent configs, tools, and chat history\n",
    "- Runs the LangGraph ReAct agent **locally** (same code as the agent pod)\n",
    "- Shows every tool call, tool response, and LLM reasoning step\n",
    "- Displays media items returned by tools\n",
    "\n",
    "**Prerequisites:**\n",
    "```bash\n",
    "pip install langgraph langchain-anthropic langchain-openai httpx ipywidgets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configuration ─────────────────────────────────────────────\n",
    "# Point this at your running Falcon-Eye API\n",
    "API_URL = \"http://localhost:8000\"   # <-- CHANGE THIS to your backend URL\n",
    "INTERNAL_API_KEY = \"\"               # <-- Set if your API requires X-Internal-Key\n",
    "\n",
    "# LLM config (override per-agent if needed)\n",
    "LLM_PROVIDER = \"openai\"            # openai | anthropic | ollama\n",
    "LLM_MODEL = \"gpt-4.1\"              # model name\n",
    "LLM_API_KEY = \"\"                    # <-- Set your API key here\n",
    "LLM_BASE_URL = \"\"                  # Only needed for ollama / custom endpoints\n",
    "\n",
    "# Agent to test (leave empty to list available agents)\n",
    "AGENT_ID = \"\"                       # <-- Paste agent UUID here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup: add agent code to path & imports ──────────────────\n",
    "import sys, os\n",
    "\n",
    "# Make sure we can import from the agent directory\n",
    "AGENT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "if AGENT_DIR not in sys.path:\n",
    "    sys.path.insert(0, AGENT_DIR)\n",
    "\n",
    "# Set env vars before importing agent modules\n",
    "os.environ[\"API_URL\"] = API_URL\n",
    "os.environ[\"INTERNAL_API_KEY\"] = INTERNAL_API_KEY\n",
    "os.environ[\"AGENT_ID\"] = AGENT_ID or \"\"\n",
    "\n",
    "import json\n",
    "import asyncio\n",
    "import httpx\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from tool_executor import build_tools\n",
    "from main import get_llm\n",
    "\n",
    "def _headers():\n",
    "    h = {}\n",
    "    if INTERNAL_API_KEY:\n",
    "        h[\"X-Internal-Key\"] = INTERNAL_API_KEY\n",
    "    return h\n",
    "\n",
    "async def api_get(path: str):\n",
    "    async with httpx.AsyncClient(timeout=30, headers=_headers()) as c:\n",
    "        res = await c.get(f\"{API_URL}{path}\")\n",
    "        res.raise_for_status()\n",
    "        return res.json()\n",
    "\n",
    "async def api_post(path: str, data: dict):\n",
    "    async with httpx.AsyncClient(timeout=30, headers=_headers()) as c:\n",
    "        res = await c.post(f\"{API_URL}{path}\", json=data)\n",
    "        res.raise_for_status()\n",
    "        return res.json()\n",
    "\n",
    "print(\"Imports OK. Connecting to:\", API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── List Available Agents ────────────────────────────────────\n",
    "agents_resp = await api_get(\"/api/agents/\")\n",
    "agents = agents_resp.get(\"agents\", [])\n",
    "\n",
    "if not agents:\n",
    "    print(\"No agents found. Create one in the dashboard first.\")\n",
    "else:\n",
    "    print(f\"Found {len(agents)} agent(s):\\n\")\n",
    "    for a in agents:\n",
    "        tools_str = \", \".join(a.get(\"tools\", [])[:5])\n",
    "        if len(a.get(\"tools\", [])) > 5:\n",
    "            tools_str += f\" (+{len(a['tools'])-5} more)\"\n",
    "        print(f\"  {a['name']}\")\n",
    "        print(f\"    ID:       {a['id']}\")\n",
    "        print(f\"    Provider: {a['provider']} / {a['model']}\")\n",
    "        print(f\"    Status:   {a['status']}\")\n",
    "        print(f\"    Channel:  {a.get('channel_type') or 'none'}\")\n",
    "        print(f\"    Tools:    {tools_str or 'none'}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load Agent Config ────────────────────────────────────────\n",
    "# Set AGENT_ID above, or pick one from the list:\n",
    "if not AGENT_ID:\n",
    "    if agents:\n",
    "        AGENT_ID = agents[0][\"id\"]\n",
    "        print(f\"Auto-selected first agent: {agents[0]['name']} ({AGENT_ID})\")\n",
    "    else:\n",
    "        raise ValueError(\"No agents available. Set AGENT_ID or create an agent first.\")\n",
    "\n",
    "config = await api_get(f\"/api/agents/{AGENT_ID}/chat-config\")\n",
    "\n",
    "# Allow local overrides\n",
    "provider = LLM_PROVIDER or config[\"provider\"]\n",
    "model = LLM_MODEL or config[\"model\"]\n",
    "api_key = LLM_API_KEY or config.get(\"api_key\", \"\")\n",
    "system_prompt = config.get(\"system_prompt\", \"You are a helpful AI assistant.\")\n",
    "tools_schema = config.get(\"tools_schema\", [])\n",
    "max_tokens = config.get(\"max_tokens\", 4096)\n",
    "temperature = config.get(\"temperature\", 0.7)\n",
    "\n",
    "print(f\"Agent:    {AGENT_ID}\")\n",
    "print(f\"Provider: {provider}\")\n",
    "print(f\"Model:    {model}\")\n",
    "print(f\"Tools:    {len(tools_schema)}\")\n",
    "if tools_schema:\n",
    "    for t in tools_schema:\n",
    "        fn = t[\"function\"]\n",
    "        print(f\"  - {fn['name']}: {fn['description'][:80]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Build the LangGraph Agent ────────────────────────────────\n",
    "import uuid as _uuid\n",
    "\n",
    "SESSION_ID = str(_uuid.uuid4())\n",
    "\n",
    "agent_ctx = {\n",
    "    \"provider\": provider,\n",
    "    \"model\": model,\n",
    "    \"api_key\": api_key,\n",
    "    \"agent_id\": AGENT_ID,\n",
    "    \"session_id\": SESSION_ID,\n",
    "}\n",
    "\n",
    "media_collector: list[dict] = []\n",
    "tools = build_tools(tools_schema, media_collector, API_URL, agent_ctx)\n",
    "\n",
    "llm = get_llm(provider, model, api_key, temperature, max_tokens, base_url=LLM_BASE_URL)\n",
    "agent = create_react_agent(model=llm, tools=tools)\n",
    "\n",
    "# Inject tools list into the system prompt (same as production)\n",
    "if tools_schema:\n",
    "    tool_lines = [f\"- **{t['function']['name']}**: {t['function']['description']}\" for t in tools_schema]\n",
    "    system_prompt += (\n",
    "        \"\\n\\n## Available Tools\\n\"\n",
    "        \"You MUST use the appropriate tool when the user's request matches one. \"\n",
    "        \"Do not describe what you would do — actually call the tool.\\n\\n\"\n",
    "        + \"\\n\".join(tool_lines)\n",
    "    )\n",
    "\n",
    "conversation = [SystemMessage(content=system_prompt)]\n",
    "\n",
    "print(f\"Agent ready. Session: {SESSION_ID}\")\n",
    "print(f\"Tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Helper: Run a single message and display full trace ─────\n",
    "\n",
    "def _fmt_tool_args(args):\n",
    "    \"\"\"Pretty-format tool arguments.\"\"\"\n",
    "    if not args:\n",
    "        return \"(no arguments)\"\n",
    "    try:\n",
    "        return json.dumps(args, indent=2)\n",
    "    except Exception:\n",
    "        return str(args)\n",
    "\n",
    "def _truncate(text, limit=2000):\n",
    "    if len(text) <= limit:\n",
    "        return text\n",
    "    return text[:limit] + f\"\\n... ({len(text) - limit} chars truncated)\"\n",
    "\n",
    "\n",
    "async def chat(user_message: str, max_steps: int = 25, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Send a message to the agent and display the full execution trace.\n",
    "    \n",
    "    Returns (response_text, media_items, token_usage).\n",
    "    \"\"\"\n",
    "    media_collector.clear()\n",
    "    conversation.append(HumanMessage(content=user_message))\n",
    "    \n",
    "    if verbose:\n",
    "        display(Markdown(f\"---\\n**You:** {user_message}\"))\n",
    "    \n",
    "    response_text = \"\"\n",
    "    total_input = 0\n",
    "    total_output = 0\n",
    "    step_num = 0\n",
    "    tool_calls_log = []\n",
    "    \n",
    "    try:\n",
    "        async for step in agent.astream(\n",
    "            {\"messages\": conversation},\n",
    "            config={\"recursion_limit\": max_steps},\n",
    "            stream_mode=\"updates\",\n",
    "        ):\n",
    "            for node_name, node_output in step.items():\n",
    "                for msg in node_output.get(\"messages\", []):\n",
    "                    step_num += 1\n",
    "                    \n",
    "                    if isinstance(msg, AIMessage):\n",
    "                        # Track token usage\n",
    "                        usage = getattr(msg, \"usage_metadata\", None)\n",
    "                        if usage and isinstance(usage, dict):\n",
    "                            total_input += usage.get(\"input_tokens\", 0)\n",
    "                            total_output += usage.get(\"output_tokens\", 0)\n",
    "                        \n",
    "                        # Tool calls\n",
    "                        if msg.tool_calls:\n",
    "                            for tc in msg.tool_calls:\n",
    "                                tool_entry = {\n",
    "                                    \"step\": step_num,\n",
    "                                    \"tool\": tc[\"name\"],\n",
    "                                    \"args\": tc[\"args\"],\n",
    "                                    \"id\": tc[\"id\"],\n",
    "                                }\n",
    "                                tool_calls_log.append(tool_entry)\n",
    "                                \n",
    "                                if verbose:\n",
    "                                    display(Markdown(\n",
    "                                        f\"**Step {step_num} — Tool Call:** `{tc['name']}`\\n\"\n",
    "                                        f\"```json\\n{_fmt_tool_args(tc['args'])}\\n```\"\n",
    "                                    ))\n",
    "                        \n",
    "                        # Final text response\n",
    "                        if msg.content and not msg.tool_calls:\n",
    "                            response_text = msg.content\n",
    "                            conversation.append(msg)\n",
    "                    \n",
    "                    elif isinstance(msg, ToolMessage):\n",
    "                        # Match back to the tool call\n",
    "                        tool_name = \"unknown\"\n",
    "                        for entry in tool_calls_log:\n",
    "                            if entry[\"id\"] == msg.tool_call_id:\n",
    "                                tool_name = entry[\"tool\"]\n",
    "                                entry[\"response\"] = msg.content\n",
    "                                break\n",
    "                        \n",
    "                        if verbose:\n",
    "                            content_str = msg.content if isinstance(msg.content, str) else json.dumps(msg.content, indent=2)\n",
    "                            display(Markdown(\n",
    "                                f\"**Step {step_num} — Tool Response** (`{tool_name}`)**:**\\n\"\n",
    "                                f\"```\\n{_truncate(content_str)}\\n```\"\n",
    "                            ))\n",
    "    \n",
    "    except Exception as e:\n",
    "        err_type = type(e).__name__\n",
    "        if \"recursion\" in str(e).lower():\n",
    "            display(Markdown(f\"**Hit recursion limit ({max_steps} steps).** Partial response below.\"))\n",
    "        else:\n",
    "            display(Markdown(f\"**Error ({err_type}):** {e}\"))\n",
    "            raise\n",
    "    \n",
    "    # Display final response\n",
    "    if verbose:\n",
    "        display(Markdown(f\"---\\n**Agent Response:**\\n\\n{response_text}\"))\n",
    "    \n",
    "    # Display media\n",
    "    if media_collector:\n",
    "        if verbose:\n",
    "            display(Markdown(f\"**Media Items ({len(media_collector)}):**\"))\n",
    "            for i, m in enumerate(media_collector):\n",
    "                path = m.get('path', 'N/A')\n",
    "                mtype = m.get('media_type', 'unknown')\n",
    "                caption = m.get('caption', '')\n",
    "                url = m.get('url', '')\n",
    "                display(Markdown(\n",
    "                    f\"{i+1}. **{mtype}** — `{path}`\\n\"\n",
    "                    f\"   - URL: `{url}`\\n\"\n",
    "                    f\"   - Caption: {caption or '(none)'}\\n\"\n",
    "                    f\"   - Size: {m.get('size', '?')} bytes\"\n",
    "                ))\n",
    "    \n",
    "    # Token summary\n",
    "    if verbose:\n",
    "        display(Markdown(\n",
    "            f\"---\\n*Tokens: {total_input} in / {total_output} out | \"\n",
    "            f\"Steps: {step_num} | Tool calls: {len(tool_calls_log)} | \"\n",
    "            f\"Media: {len(media_collector)}*\"\n",
    "        ))\n",
    "    \n",
    "    return {\n",
    "        \"response\": response_text,\n",
    "        \"media\": list(media_collector),\n",
    "        \"tool_calls\": tool_calls_log,\n",
    "        \"tokens\": {\"input\": total_input, \"output\": total_output},\n",
    "        \"steps\": step_num,\n",
    "    }\n",
    "\n",
    "print(\"chat() helper ready. Use: result = await chat('your message')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Messages\n",
    "\n",
    "Run the cell below to test. Change the message and re-run as needed.\n",
    "The conversation history is maintained across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Test: Send a message ─────────────────────────────────────\n",
    "result = await chat(\"List all cameras and their status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Test: Follow-up (conversation continues) ─────────────────\n",
    "result = await chat(\"How many nodes are in the cluster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Test: Media tool (snapshot/recording) ────────────────────\n",
    "# Uncomment and set camera_id to test:\n",
    "# result = await chat(\"Take a snapshot of camera <camera_id> and send it to me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Inspect: raw tool calls and responses ────────────────────\n",
    "if result[\"tool_calls\"]:\n",
    "    print(f\"Tool calls from last interaction ({len(result['tool_calls'])}):\\n\")\n",
    "    for tc in result[\"tool_calls\"]:\n",
    "        print(f\"  [{tc['step']}] {tc['tool']}\")\n",
    "        print(f\"      Args: {json.dumps(tc['args'], indent=8)}\")\n",
    "        resp = tc.get('response', '(pending)')\n",
    "        if isinstance(resp, str) and len(resp) > 300:\n",
    "            resp = resp[:300] + '...'\n",
    "        print(f\"      Response: {resp}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No tool calls in last interaction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Inspect: full conversation history ───────────────────────\n",
    "print(f\"Conversation ({len(conversation)} messages):\\n\")\n",
    "for i, msg in enumerate(conversation):\n",
    "    role = type(msg).__name__.replace(\"Message\", \"\")\n",
    "    content = msg.content if isinstance(msg.content, str) else str(msg.content)\n",
    "    if len(content) > 200:\n",
    "        content = content[:200] + \"...\"\n",
    "    print(f\"  [{i}] {role}: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Reset conversation ───────────────────────────────────────\n",
    "# Uncomment to start fresh:\n",
    "# conversation.clear()\n",
    "# conversation.append(SystemMessage(content=system_prompt))\n",
    "# media_collector.clear()\n",
    "# print(\"Conversation reset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Tool Testing\n",
    "\n",
    "Call tools directly without going through the LLM. Useful for debugging tool behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Direct tool execution (bypasses LLM) ─────────────────────\n",
    "async def call_tool(tool_name: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Execute a tool directly via the API, bypassing the LLM.\n",
    "    Shows the raw result and any media items.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"tool_name\": tool_name,\n",
    "        \"arguments\": kwargs,\n",
    "        \"agent_context\": agent_ctx,\n",
    "    }\n",
    "    \n",
    "    display(Markdown(f\"**Calling tool:** `{tool_name}`\\n```json\\n{json.dumps(kwargs, indent=2)}\\n```\"))\n",
    "    \n",
    "    result = await api_post(\"/api/tools/execute\", payload)\n",
    "    \n",
    "    tool_result = result.get(\"result\", \"\")\n",
    "    tool_media = result.get(\"media\", [])\n",
    "    \n",
    "    display(Markdown(f\"**Result:**\\n```\\n{_truncate(tool_result)}\\n```\"))\n",
    "    \n",
    "    if tool_media:\n",
    "        display(Markdown(f\"**Media ({len(tool_media)} items):**\"))\n",
    "        for m in tool_media:\n",
    "            display(Markdown(f\"- `{m.get('path', 'N/A')}` ({m.get('media_type', '?')}) — {m.get('caption', '')}\"))\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"call_tool() ready. Usage: result = await call_tool('list_cameras')\")\n",
    "print(\"\\nAvailable tools:\")\n",
    "for t in tools_schema:\n",
    "    fn = t[\"function\"]\n",
    "    params = [p for p in fn.get(\"parameters\", {}).get(\"properties\", {}).keys()]\n",
    "    print(f\"  {fn['name']}({', '.join(params)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Example: call a tool directly ────────────────────────────\n",
    "result = await call_tool(\"list_cameras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Example: call tool with arguments ─────────────────────────\n",
    "# result = await call_tool(\"camera_status\", camera_id=\"YOUR-CAMERA-UUID\")\n",
    "# result = await call_tool(\"list_recordings\")\n",
    "# result = await call_tool(\"system_info\")\n",
    "# result = await call_tool(\"list_files\", prefix=\"snapshots\")\n",
    "# result = await call_tool(\"send_media\", path=\"snapshots/my_file.jpg\", caption=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch / Stress Testing\n",
    "\n",
    "Run multiple prompts in sequence and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Batch test: run multiple prompts ─────────────────────────\n",
    "test_prompts = [\n",
    "    \"What cameras are online right now?\",\n",
    "    \"How many nodes does the cluster have?\",\n",
    "    \"Give me a system overview\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "for prompt in test_prompts:\n",
    "    # Reset conversation for each test\n",
    "    conversation.clear()\n",
    "    conversation.append(SystemMessage(content=system_prompt))\n",
    "    media_collector.clear()\n",
    "    \n",
    "    r = await chat(prompt, verbose=False)\n",
    "    results.append({\"prompt\": prompt, **r})\n",
    "    \n",
    "    status = \"OK\" if r[\"response\"] else \"EMPTY\"\n",
    "    print(f\"  [{status}] {prompt}\")\n",
    "    print(f\"       -> {len(r['response'])} chars, {r['tokens']['input']}+{r['tokens']['output']} tokens, {len(r['tool_calls'])} tools\")\n",
    "\n",
    "print(f\"\\nDone: {len(results)} tests\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
