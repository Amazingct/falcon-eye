{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Falcon-Eye Agent Test Notebook\n",
        "\n",
        "Test agents locally by connecting to a running Falcon-Eye API backend.\n",
        "\n",
        "**What this does:**\n",
        "1. Logs in to the API with your username & password (JWT auth)\n",
        "2. Fetches agent configs, tools, and chat history from the backend\n",
        "3. Runs the LangGraph ReAct agent **locally** (same code as the agent pod)\n",
        "4. Shows every tool call, tool response, and LLM reasoning step\n",
        "5. Displays media items returned by tools\n",
        "\n",
        "**Prerequisites:**\n",
        "```bash\n",
        "pip install langgraph langchain-anthropic langchain-openai httpx ipywidgets\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Configuration ─────────────────────────────────────────────\n",
        "# Point this at your running Falcon-Eye API\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "API_URL = \"http://192.168.1.142:31017\"   # <-- CHANGE THIS to your backend URL\n",
        "INTERNAL_API_KEY = \"\"               # <-- Set if your API requires X-Internal-Key\n",
        "\n",
        "# LLM config (override per-agent if needed)\n",
        "LLM_PROVIDER = \"openai\"            # openai | anthropic | ollama\n",
        "LLM_MODEL = \"gpt-4.1\"              # model name\n",
        "LLM_API_KEY = os.getenv(\"OPENAI_API_KEY\")                 # <-- Set your API key here\n",
        "LLM_BASE_URL = \"\"                  # Only needed for ollama / custom endpoints\n",
        "\n",
        "# Agent to test (leave empty to list available agents)\n",
        "AGENT_ID = \"\"                       # <-- Paste agent UUID here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST http://192.168.1.142:31017/api/auth/login \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in as: admin\n",
            "Token: eyJhbGciOiJIUzI1NiIs...\n"
          ]
        }
      ],
      "source": [
        "# ── Login ─────────────────────────────────────────────────────\n",
        "# Authenticates with the Falcon-Eye API and stores the JWT token.\n",
        "import getpass\n",
        "import httpx\n",
        "\n",
        "_username = input(\"Username: \")\n",
        "_password = getpass.getpass(\"Password: \")\n",
        "\n",
        "async def _do_login():\n",
        "    async with httpx.AsyncClient(timeout=15) as c:\n",
        "        res = await c.post(f\"{API_URL}/api/auth/login\", json={\"username\": _username, \"password\": _password})\n",
        "        if res.status_code == 200:\n",
        "            return res.json()\n",
        "        elif res.status_code == 401:\n",
        "            raise ValueError(\"Invalid username or password.\")\n",
        "        elif res.status_code == 400:\n",
        "            raise ValueError(\"Auth not set up on this server. Run setup from the dashboard first.\")\n",
        "        else:\n",
        "            raise ValueError(f\"Login failed ({res.status_code}): {res.text[:200]}\")\n",
        "\n",
        "_login_resp = await _do_login()\n",
        "AUTH_TOKEN = _login_resp[\"token\"]\n",
        "\n",
        "del _password  # don't keep plaintext password in memory\n",
        "\n",
        "print(f\"Logged in as: {_login_resp['username']}\")\n",
        "print(f\"Token: {AUTH_TOKEN[:20]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in. Connecting to: http://192.168.1.142:31017\n"
          ]
        }
      ],
      "source": [
        "# ── Setup: add agent code to path & imports ──────────────────\n",
        "import sys, os\n",
        "\n",
        "# Make sure we can import from the agent directory\n",
        "AGENT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "if AGENT_DIR not in sys.path:\n",
        "    sys.path.insert(0, AGENT_DIR)\n",
        "\n",
        "# Set env vars before importing agent modules\n",
        "os.environ[\"API_URL\"] = API_URL\n",
        "os.environ[\"INTERNAL_API_KEY\"] = INTERNAL_API_KEY\n",
        "os.environ[\"AGENT_ID\"] = AGENT_ID or \"\"\n",
        "\n",
        "import json\n",
        "import asyncio\n",
        "import httpx\n",
        "from datetime import datetime\n",
        "from IPython.display import display, Markdown, HTML, Image\n",
        "\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "from tool_executor import build_tools\n",
        "from main import get_llm\n",
        "\n",
        "def _headers():\n",
        "    h = {\"Authorization\": f\"Bearer {AUTH_TOKEN}\"}\n",
        "    if INTERNAL_API_KEY:\n",
        "        h[\"X-Internal-Key\"] = INTERNAL_API_KEY\n",
        "    return h\n",
        "\n",
        "async def api_get(path: str):\n",
        "    async with httpx.AsyncClient(timeout=30, headers=_headers()) as c:\n",
        "        res = await c.get(f\"{API_URL}{path}\")\n",
        "        res.raise_for_status()\n",
        "        return res.json()\n",
        "\n",
        "async def api_post(path: str, data: dict):\n",
        "    async with httpx.AsyncClient(timeout=30, headers=_headers()) as c:\n",
        "        res = await c.post(f\"{API_URL}{path}\", json=data)\n",
        "        res.raise_for_status()\n",
        "        return res.json()\n",
        "\n",
        "print(\"Logged in. Connecting to:\", API_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET http://192.168.1.142:31017/api/agents/ \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 agent(s):\n",
            "\n",
            "  Main Assistant\n",
            "    ID:       e428ec5e-7e22-424c-8a80-86e993337743\n",
            "    Provider: openai / gpt-4.1\n",
            "    Status:   running\n",
            "    Channel:  none\n",
            "    Tools:    camera_list, camera_status, camera_control, camera_snapshot, recording_start (+23 more)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ── List Available Agents ────────────────────────────────────\n",
        "agents_resp = await api_get(\"/api/agents/\")\n",
        "agents = agents_resp.get(\"agents\", [])\n",
        "\n",
        "if not agents:\n",
        "    print(\"No agents found. Create one in the dashboard first.\")\n",
        "else:\n",
        "    print(f\"Found {len(agents)} agent(s):\\n\")\n",
        "    for a in agents:\n",
        "        tools_str = \", \".join(a.get(\"tools\", [])[:5])\n",
        "        if len(a.get(\"tools\", [])) > 5:\n",
        "            tools_str += f\" (+{len(a['tools'])-5} more)\"\n",
        "        print(f\"  {a['name']}\")\n",
        "        print(f\"    ID:       {a['id']}\")\n",
        "        print(f\"    Provider: {a['provider']} / {a['model']}\")\n",
        "        print(f\"    Status:   {a['status']}\")\n",
        "        print(f\"    Channel:  {a.get('channel_type') or 'none'}\")\n",
        "        print(f\"    Tools:    {tools_str or 'none'}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET http://192.168.1.142:31017/api/agents/e428ec5e-7e22-424c-8a80-86e993337743/chat-config \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auto-selected first agent: Main Assistant (e428ec5e-7e22-424c-8a80-86e993337743)\n",
            "Agent:    e428ec5e-7e22-424c-8a80-86e993337743\n",
            "Provider: openai\n",
            "Model:    gpt-4.1\n",
            "Tools:    28\n",
            "  - list_cameras: Get all cameras and their current status\n",
            "  - camera_status: Check if a specific camera is online\n",
            "  - control_camera: Start, stop, or restart a camera\n",
            "  - camera_snapshot: Grab a snapshot frame from a running camera and save it to the filesystem. Retur\n",
            "  - start_recording: Start recording on a camera\n",
            "  - stop_recording: Stop an active recording on a camera\n",
            "  - list_recordings: Get all recordings, optionally filtered by camera\n",
            "  - get_recording: Get details and download URL for a specific recording. Use this to get the URL b\n",
            "  - send_recording: Send a recording to the user's chat as an inline video. Accepts a recording ID (\n",
            "  - list_nodes: Get cluster nodes and their health status\n",
            "  - scan_cameras: Scan cluster nodes for USB and network cameras\n",
            "  - system_info: Get cluster resource usage and pod status\n",
            "  - send_alert: Send an alert via configured channels\n",
            "  - web_search: Search the web (requires API key)\n",
            "  - spawn_agent: Create and start a new agent. Inherits calling agent's LLM config. If 'task' is \n",
            "  - delegate_task: Send a task to an already-running agent asynchronously. Returns immediately so y\n",
            "  - clone_agent: Create a new agent by cloning an existing agent's configuration\n",
            "  - create_cron_job: Create a scheduled cron job that sends a prompt to you on a recurring schedule. \n",
            "  - list_cron_jobs: List all your scheduled cron jobs with their schedule, status, and last run resu\n",
            "  - delete_cron_job: Delete a scheduled cron job by ID.\n",
            "  - analyze_camera: Capture frames from a camera and analyze what's happening using vision AI. In 'c\n",
            "  - custom_api_call: Call a user-defined HTTP endpoint\n",
            "  - write_file: Write text content to a file in the shared agent filesystem. Creates parent dire\n",
            "  - read_file: Read the contents of a text file from the shared agent filesystem.\n",
            "  - list_files: List files and directories in the shared agent filesystem. Use a prefix to brows\n",
            "  - send_media: Send an image, video, or document from the shared filesystem to the user's chat.\n",
            "  - deliver_media_message: Deliver media files as a structured chat message. Use this to send images/videos\n",
            "  - delete_file: Delete a file from the shared agent filesystem.\n"
          ]
        }
      ],
      "source": [
        "# ── Load Agent Config ────────────────────────────────────────\n",
        "# Set AGENT_ID above, or pick one from the list:\n",
        "if not AGENT_ID:\n",
        "    if agents:\n",
        "        AGENT_ID = agents[0][\"id\"]\n",
        "        print(f\"Auto-selected first agent: {agents[0]['name']} ({AGENT_ID})\")\n",
        "    else:\n",
        "        raise ValueError(\"No agents available. Set AGENT_ID or create an agent first.\")\n",
        "\n",
        "config = await api_get(f\"/api/agents/{AGENT_ID}/chat-config\")\n",
        "\n",
        "# Allow local overrides\n",
        "provider = LLM_PROVIDER or config[\"provider\"]\n",
        "model = LLM_MODEL or config[\"model\"]\n",
        "api_key = LLM_API_KEY or config.get(\"api_key\", \"\")\n",
        "system_prompt = config.get(\"system_prompt\", \"You are a helpful AI assistant.\")\n",
        "tools_schema = config.get(\"tools_schema\", [])\n",
        "max_tokens = config.get(\"max_tokens\", 4096)\n",
        "temperature = config.get(\"temperature\", 0.7)\n",
        "\n",
        "print(f\"Agent:    {AGENT_ID}\")\n",
        "print(f\"Provider: {provider}\")\n",
        "print(f\"Model:    {model}\")\n",
        "print(f\"Tools:    {len(tools_schema)}\")\n",
        "if tools_schema:\n",
        "    for t in tools_schema:\n",
        "        fn = t[\"function\"]\n",
        "        print(f\"  - {fn['name']}: {fn['description'][:80]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent ready. Session: aec5cbdc-e936-4fec-ae63-dc605994e17f\n",
            "Tools: ['list_cameras', 'camera_status', 'control_camera', 'camera_snapshot', 'start_recording', 'stop_recording', 'list_recordings', 'get_recording', 'send_recording', 'list_nodes', 'scan_cameras', 'system_info', 'send_alert', 'web_search', 'spawn_agent', 'delegate_task', 'clone_agent', 'create_cron_job', 'list_cron_jobs', 'delete_cron_job', 'analyze_camera', 'custom_api_call', 'write_file', 'read_file', 'list_files', 'send_media', 'deliver_media_message', 'delete_file']\n"
          ]
        }
      ],
      "source": [
        "# ── Build the LangGraph Agent ────────────────────────────────\n",
        "import uuid as _uuid\n",
        "from langchain_core.tools import StructuredTool\n",
        "from tool_executor import _schema_to_pydantic\n",
        "\n",
        "SESSION_ID = str(_uuid.uuid4())\n",
        "\n",
        "agent_ctx = {\n",
        "    \"provider\": provider,\n",
        "    \"model\": model,\n",
        "    \"api_key\": api_key,\n",
        "    \"agent_id\": AGENT_ID,\n",
        "    \"session_id\": SESSION_ID,\n",
        "}\n",
        "\n",
        "# Build tools with JWT auth (build_tools uses INTERNAL_API_KEY which we\n",
        "# don't have locally, so we build auth-aware tools directly)\n",
        "media_collector: list[dict] = []\n",
        "\n",
        "def _build_local_tools(schemas, media_col, base_url, ctx):\n",
        "    \"\"\"Like build_tools but includes the JWT Bearer token for local testing.\"\"\"\n",
        "    _tools = []\n",
        "    for schema in schemas:\n",
        "        fn = schema[\"function\"]\n",
        "        name = fn[\"name\"]\n",
        "        desc = fn[\"description\"]\n",
        "        params = fn.get(\"parameters\", {\"type\": \"object\", \"properties\": {}})\n",
        "        args_model = _schema_to_pydantic(name, params)\n",
        "\n",
        "        async def _execute(__tool_name=name, __ctx=ctx, __media=media_col, **kwargs):\n",
        "            payload = {\"tool_name\": __tool_name, \"arguments\": kwargs}\n",
        "            if __ctx:\n",
        "                payload[\"agent_context\"] = __ctx\n",
        "            async with httpx.AsyncClient(base_url=base_url, timeout=60, headers=_headers()) as client:\n",
        "                res = await client.post(\"/api/tools/execute\", json=payload)\n",
        "                if res.status_code == 200:\n",
        "                    data = res.json()\n",
        "                    for item in data.get(\"media\", []):\n",
        "                        __media.append(item)\n",
        "                    return data.get(\"result\", \"No result returned\")\n",
        "                return f\"Tool error ({res.status_code}): {res.text[:300]}\"\n",
        "\n",
        "        _tools.append(StructuredTool.from_function(\n",
        "            coroutine=_execute, name=name, description=desc, args_schema=args_model,\n",
        "        ))\n",
        "    return _tools\n",
        "\n",
        "tools = _build_local_tools(tools_schema, media_collector, API_URL, agent_ctx)\n",
        "\n",
        "llm = get_llm(provider, model, api_key, temperature, max_tokens, base_url=LLM_BASE_URL)\n",
        "agent = create_react_agent(model=llm, tools=tools)\n",
        "\n",
        "# Inject tools list into the system prompt (same as production)\n",
        "if tools_schema:\n",
        "    tool_lines = [f\"- **{t['function']['name']}**: {t['function']['description']}\" for t in tools_schema]\n",
        "    system_prompt += (\n",
        "        \"\\n\\n## Available Tools\\n\"\n",
        "        \"You MUST use the appropriate tool when the user's request matches one. \"\n",
        "        \"Do not describe what you would do — actually call the tool.\\n\\n\"\n",
        "        + \"\\n\".join(tool_lines)\n",
        "    )\n",
        "\n",
        "conversation = [SystemMessage(content=system_prompt)]\n",
        "\n",
        "print(f\"Agent ready. Session: {SESSION_ID}\")\n",
        "print(f\"Tools: {[t.name for t in tools]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chat() helper ready. Use: result = await chat('your message')\n"
          ]
        }
      ],
      "source": [
        "# ── Helper: Run a single message and display full trace ─────\n",
        "\n",
        "def _fmt_tool_args(args):\n",
        "    \"\"\"Pretty-format tool arguments.\"\"\"\n",
        "    if not args:\n",
        "        return \"(no arguments)\"\n",
        "    try:\n",
        "        return json.dumps(args, indent=2)\n",
        "    except Exception:\n",
        "        return str(args)\n",
        "\n",
        "def _truncate(text, limit=2000):\n",
        "    if len(text) <= limit:\n",
        "        return text\n",
        "    return text[:limit] + f\"\\n... ({len(text) - limit} chars truncated)\"\n",
        "\n",
        "\n",
        "async def chat(user_message: str, max_steps: int = 25, verbose: bool = True):\n",
        "    \"\"\"\n",
        "    Send a message to the agent and display the full execution trace.\n",
        "    \n",
        "    Returns (response_text, media_items, token_usage).\n",
        "    \"\"\"\n",
        "    media_collector.clear()\n",
        "    conversation.append(HumanMessage(content=user_message))\n",
        "    \n",
        "    if verbose:\n",
        "        display(Markdown(f\"---\\n**You:** {user_message}\"))\n",
        "    \n",
        "    response_text = \"\"\n",
        "    total_input = 0\n",
        "    total_output = 0\n",
        "    step_num = 0\n",
        "    tool_calls_log = []\n",
        "    \n",
        "    try:\n",
        "        async for step in agent.astream(\n",
        "            {\"messages\": conversation},\n",
        "            config={\"recursion_limit\": max_steps},\n",
        "            stream_mode=\"updates\",\n",
        "        ):\n",
        "            for node_name, node_output in step.items():\n",
        "                for msg in node_output.get(\"messages\", []):\n",
        "                    step_num += 1\n",
        "                    \n",
        "                    if isinstance(msg, AIMessage):\n",
        "                        # Track token usage\n",
        "                        usage = getattr(msg, \"usage_metadata\", None)\n",
        "                        if usage and isinstance(usage, dict):\n",
        "                            total_input += usage.get(\"input_tokens\", 0)\n",
        "                            total_output += usage.get(\"output_tokens\", 0)\n",
        "                        \n",
        "                        # Tool calls\n",
        "                        if msg.tool_calls:\n",
        "                            for tc in msg.tool_calls:\n",
        "                                tool_entry = {\n",
        "                                    \"step\": step_num,\n",
        "                                    \"tool\": tc[\"name\"],\n",
        "                                    \"args\": tc[\"args\"],\n",
        "                                    \"id\": tc[\"id\"],\n",
        "                                }\n",
        "                                tool_calls_log.append(tool_entry)\n",
        "                                \n",
        "                                if verbose:\n",
        "                                    display(Markdown(\n",
        "                                        f\"**Step {step_num} — Tool Call:** `{tc['name']}`\\n\"\n",
        "                                        f\"```json\\n{_fmt_tool_args(tc['args'])}\\n```\"\n",
        "                                    ))\n",
        "                        \n",
        "                        # Final text response\n",
        "                        if msg.content and not msg.tool_calls:\n",
        "                            response_text = msg.content\n",
        "                            conversation.append(msg)\n",
        "                    \n",
        "                    elif isinstance(msg, ToolMessage):\n",
        "                        # Match back to the tool call\n",
        "                        tool_name = \"unknown\"\n",
        "                        for entry in tool_calls_log:\n",
        "                            if entry[\"id\"] == msg.tool_call_id:\n",
        "                                tool_name = entry[\"tool\"]\n",
        "                                entry[\"response\"] = msg.content\n",
        "                                break\n",
        "                        \n",
        "                        if verbose:\n",
        "                            content_str = msg.content if isinstance(msg.content, str) else json.dumps(msg.content, indent=2)\n",
        "                            display(Markdown(\n",
        "                                f\"**Step {step_num} — Tool Response** (`{tool_name}`)**:**\\n\"\n",
        "                                f\"```\\n{_truncate(content_str)}\\n```\"\n",
        "                            ))\n",
        "    \n",
        "    except Exception as e:\n",
        "        err_type = type(e).__name__\n",
        "        if \"recursion\" in str(e).lower():\n",
        "            display(Markdown(f\"**Hit recursion limit ({max_steps} steps).** Partial response below.\"))\n",
        "        else:\n",
        "            display(Markdown(f\"**Error ({err_type}):** {e}\"))\n",
        "            raise\n",
        "    \n",
        "    # Display final response\n",
        "    if verbose:\n",
        "        display(Markdown(f\"---\\n**Agent Response:**\\n\\n{response_text}\"))\n",
        "    \n",
        "    # Display media\n",
        "    if media_collector:\n",
        "        if verbose:\n",
        "            display(Markdown(f\"**Media Items ({len(media_collector)}):**\"))\n",
        "            for i, m in enumerate(media_collector):\n",
        "                path = m.get('path', 'N/A')\n",
        "                mtype = m.get('media_type', 'unknown')\n",
        "                caption = m.get('caption', '')\n",
        "                url = m.get('url', '')\n",
        "                display(Markdown(\n",
        "                    f\"{i+1}. **{mtype}** — `{path}`\\n\"\n",
        "                    f\"   - URL: `{url}`\\n\"\n",
        "                    f\"   - Caption: {caption or '(none)'}\\n\"\n",
        "                    f\"   - Size: {m.get('size', '?')} bytes\"\n",
        "                ))\n",
        "    \n",
        "    # Token summary\n",
        "    if verbose:\n",
        "        display(Markdown(\n",
        "            f\"---\\n*Tokens: {total_input} in / {total_output} out | \"\n",
        "            f\"Steps: {step_num} | Tool calls: {len(tool_calls_log)} | \"\n",
        "            f\"Media: {len(media_collector)}*\"\n",
        "        ))\n",
        "    \n",
        "    return {\n",
        "        \"response\": response_text,\n",
        "        \"media\": list(media_collector),\n",
        "        \"tool_calls\": tool_calls_log,\n",
        "        \"tokens\": {\"input\": total_input, \"output\": total_output},\n",
        "        \"steps\": step_num,\n",
        "    }\n",
        "\n",
        "print(\"chat() helper ready. Use: result = await chat('your message')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Send Messages\n",
        "\n",
        "Run the cell below to test. Change the message and re-run as needed.\n",
        "The conversation history is maintained across calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "---\n",
              "**You:** List all cameras and their status"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**Step 1 — Tool Call:** `list_cameras`\n",
              "```json\n",
              "(no arguments)\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST http://192.168.1.142:31017/api/tools/execute \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**Step 2 — Tool Response** (`list_cameras`)**:**\n",
              "```\n",
              "Found 1 cameras:\n",
              "- **Server Cam** (id: `503a59b2-068c-44cb-9969-ac4dd55cea22`) — running | usb on ace\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "---\n",
              "**Agent Response:**\n",
              "\n",
              "Here are the cameras and their current status:\n",
              "\n",
              "- Server Cam (ID: 503a59b2-068c-44cb-9969-ac4dd55cea22) — running (USB on node ace)\n",
              "\n",
              "Let me know if you need more details or want to control any camera!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "---\n",
              "*Tokens: 5789 in / 72 out | Steps: 3 | Tool calls: 1 | Media: 0*"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ── Test: Send a message ─────────────────────────────────────\n",
        "result = await chat(\"List all cameras and their status\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "---\n",
              "**You:** create a cronjob to send me system status everyday"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**Step 1 — Tool Call:** `create_cron_job`\n",
              "```json\n",
              "{\n",
              "  \"name\": \"Daily System Status\",\n",
              "  \"cron_expr\": \"0 0 * * *\",\n",
              "  \"prompt\": \"Provide the system status summary for the cluster, including resource usage and node health.\"\n",
              "}\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST http://192.168.1.142:31017/api/tools/execute \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**Step 2 — Tool Response** (`create_cron_job`)**:**\n",
              "```\n",
              "Cron job 'Daily System Status' created (id: 6ada4ee8-51df-4ccf-9337-e64500a2dab7).\n",
              "Schedule: `0 0 * * *` (UTC)\n",
              "Prompt: Provide the system status summary for the cluster, including resource usage and node health.\n",
              "Results will be delivered to this session.\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "---\n",
              "**Agent Response:**\n",
              "\n",
              "A cron job named \"Daily System Status\" has been created. You will receive a summary of the cluster's system status (including resource usage and node health) every day at midnight UTC. Results will be delivered here.\n",
              "\n",
              "Let me know if you want to adjust the schedule or add more details!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "---\n",
              "*Tokens: 6219 in / 107 out | Steps: 3 | Tool calls: 1 | Media: 0*"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ── Test: Follow-up (conversation continues) ─────────────────\n",
        "result = await chat(\"create a cronjob to send me system status everyday\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Test: Media tool (snapshot/recording) ────────────────────\n",
        "# Uncomment and set camera_id to test:\n",
        "# result = await chat(\"Take a snapshot of camera <camera_id> and send it to me\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Inspect: raw tool calls and responses ────────────────────\n",
        "if result[\"tool_calls\"]:\n",
        "    print(f\"Tool calls from last interaction ({len(result['tool_calls'])}):\\n\")\n",
        "    for tc in result[\"tool_calls\"]:\n",
        "        print(f\"  [{tc['step']}] {tc['tool']}\")\n",
        "        print(f\"      Args: {json.dumps(tc['args'], indent=8)}\")\n",
        "        resp = tc.get('response', '(pending)')\n",
        "        if isinstance(resp, str) and len(resp) > 300:\n",
        "            resp = resp[:300] + '...'\n",
        "        print(f\"      Response: {resp}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"No tool calls in last interaction.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Inspect: full conversation history ───────────────────────\n",
        "print(f\"Conversation ({len(conversation)} messages):\\n\")\n",
        "for i, msg in enumerate(conversation):\n",
        "    role = type(msg).__name__.replace(\"Message\", \"\")\n",
        "    content = msg.content if isinstance(msg.content, str) else str(msg.content)\n",
        "    if len(content) > 200:\n",
        "        content = content[:200] + \"...\"\n",
        "    print(f\"  [{i}] {role}: {content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Reset conversation ───────────────────────────────────────\n",
        "# Uncomment to start fresh:\n",
        "# conversation.clear()\n",
        "# conversation.append(SystemMessage(content=system_prompt))\n",
        "# media_collector.clear()\n",
        "# print(\"Conversation reset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Direct Tool Testing\n",
        "\n",
        "Call tools directly without going through the LLM. Useful for debugging tool behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Direct tool execution (bypasses LLM) ─────────────────────\n",
        "async def call_tool(tool_name: str, **kwargs):\n",
        "    \"\"\"\n",
        "    Execute a tool directly via the API, bypassing the LLM.\n",
        "    Shows the raw result and any media items.\n",
        "    \"\"\"\n",
        "    payload = {\n",
        "        \"tool_name\": tool_name,\n",
        "        \"arguments\": kwargs,\n",
        "        \"agent_context\": agent_ctx,\n",
        "    }\n",
        "    \n",
        "    display(Markdown(f\"**Calling tool:** `{tool_name}`\\n```json\\n{json.dumps(kwargs, indent=2)}\\n```\"))\n",
        "    \n",
        "    result = await api_post(\"/api/tools/execute\", payload)\n",
        "    \n",
        "    tool_result = result.get(\"result\", \"\")\n",
        "    tool_media = result.get(\"media\", [])\n",
        "    \n",
        "    display(Markdown(f\"**Result:**\\n```\\n{_truncate(tool_result)}\\n```\"))\n",
        "    \n",
        "    if tool_media:\n",
        "        display(Markdown(f\"**Media ({len(tool_media)} items):**\"))\n",
        "        for m in tool_media:\n",
        "            display(Markdown(f\"- `{m.get('path', 'N/A')}` ({m.get('media_type', '?')}) — {m.get('caption', '')}\"))\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"call_tool() ready. Usage: result = await call_tool('list_cameras')\")\n",
        "print(\"\\nAvailable tools:\")\n",
        "for t in tools_schema:\n",
        "    fn = t[\"function\"]\n",
        "    params = [p for p in fn.get(\"parameters\", {}).get(\"properties\", {}).keys()]\n",
        "    print(f\"  {fn['name']}({', '.join(params)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Example: call a tool directly ────────────────────────────\n",
        "result = await call_tool(\"list_cameras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Example: call tool with arguments ─────────────────────────\n",
        "# result = await call_tool(\"camera_status\", camera_id=\"YOUR-CAMERA-UUID\")\n",
        "# result = await call_tool(\"list_recordings\")\n",
        "# result = await call_tool(\"system_info\")\n",
        "# result = await call_tool(\"list_files\", prefix=\"snapshots\")\n",
        "# result = await call_tool(\"send_media\", path=\"snapshots/my_file.jpg\", caption=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch / Stress Testing\n",
        "\n",
        "Run multiple prompts in sequence and collect results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Batch test: run multiple prompts ─────────────────────────\n",
        "test_prompts = [\n",
        "    \"What cameras are online right now?\",\n",
        "    \"How many nodes does the cluster have?\",\n",
        "    \"Give me a system overview\",\n",
        "]\n",
        "\n",
        "results = []\n",
        "for prompt in test_prompts:\n",
        "    # Reset conversation for each test\n",
        "    conversation.clear()\n",
        "    conversation.append(SystemMessage(content=system_prompt))\n",
        "    media_collector.clear()\n",
        "    \n",
        "    r = await chat(prompt, verbose=False)\n",
        "    results.append({\"prompt\": prompt, **r})\n",
        "    \n",
        "    status = \"OK\" if r[\"response\"] else \"EMPTY\"\n",
        "    print(f\"  [{status}] {prompt}\")\n",
        "    print(f\"       -> {len(r['response'])} chars, {r['tokens']['input']}+{r['tokens']['output']} tokens, {len(r['tool_calls'])} tools\")\n",
        "\n",
        "print(f\"\\nDone: {len(results)} tests\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
